{
  "version": "https://jsonfeed.org/version/1",
  "title": "Read Rust - Performance",
  "home_page_url": "https://readrust.net/",
  "feed_url": "https://readrust.net/performance/feed.json",
  "description": "Performance posts on Read Rust",
  "author": {
    "name": "Wesley Moore",
    "url": "http://www.wezm.net/"
  },
  "items": [
    {
      "id": "80d71718-3acf-49d1-ad47-3e05c5da17a2",
      "title": "Parsing logs 230x faster with Rust",
      "content_text": "Perhaps surprisingly, one of the most challenging things about operating RubyGems.org is the logs. A single day of request logs is usually around 500 gigabytes on disk. So every day, we generate about 500 files that are 85MB on disk, and contain about a million streaming JSON objects that take up 1GB when uncompressed. What we want out of those files is incredibly tiny‚Äîa few thousand integers, labelled with names and version numbers. Without any real idea of how to get those counts out of S3, I started by writing a proof of concept Ruby script that could parse one of the 500 log files and print out stats from it. Even on my super-fast laptop, my prototype script would take more than 16 hours to parse 24 hours worth of logs.",
      "url": "https://andre.arko.net/2018/10/25/parsing-logs-230x-faster-with-rust/",
      "date_published": "2018-10-25T00:00:00+00:00",
      "author": {
        "name": "Andre Arko",
        "url": "https://plus.google.com/116392164619002275727"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "8157d765-72cb-40a0-b59f-6b4ae2ae173d",
      "title": "Rust RwLock and Mutex Performance Oddities",
      "content_text": "Recently I have been working on Rust datastructures once again. In the process I wanted to test how my work performed compared to a standard library RwLock and Mutex. On my home laptop the RwLock was 5 times faster, the Mutex 2 times faster than my work.\n\nSo checking out my code on my workplace workstation and running my bench marks I noticed the Mutex was the same - 2 times faster. However, the RwLock was 4000 times slower.",
      "url": "https://fy.blackhats.net.au/blog/html/2018/10/19/rust_rwlock_and_mutex_performance_oddities.html",
      "date_published": "2018-10-19T00:00:00+00:00",
      "author": {
        "name": "firstyear",
        "url": "https://fy.blackhats.net.au/blog/html/index.html"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "0d41cc9f-584c-4da3-8516-a567cc923279",
      "title": "Oxidizing Python: Speeding up URL quoting by 10√ó using Rust",
      "content_text": "Recently a colleague of mine told me about a small bottleneck with url quoting since we are quoting a lot of storage keys at least once when loading or storing a dataset. To speed it up, we are going to write a C-Library in Rust and invoke it from Python.",
      "url": "https://tech.blue-yonder.com/oxidizing-python-speeding-up-urlquoting-by-using-rust/",
      "date_published": "2018-10-08T10:48:12+00:00",
      "author": {
        "name": "Markus Klein",
        "url": "https://tech.blue-yonder.com/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "917520f5-6f74-4e91-87e1-40d2360c0e46",
      "title": "A Case Study in Heaptrack",
      "content_text": "When I first started building the dtparse crate, my intention was to mirror as closely as possible the equivalent Python library. Python, as you may know, is garbage collected. Very rarely is memory usage considered in Python, and I likewise wasn‚Äôt paying too much attention when dtparse was first being built.\n\nThis lackadaisical approach to memory works well enough, and I‚Äôm not planning on making dtparse hyper-efficient. But every so often, I‚Äôve wondered: ‚Äúwhat exactly is going on in memory?‚Äù",
      "url": "https://speice.io/2018/10/case-study-optimization.html",
      "date_published": "2018-10-08T00:00:00-04:00",
      "author": {
        "name": "Bradlee Speice",
        "url": "https://speice.io/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "55b31f9c-fa63-4890-bcf3-5f9b899c197f",
      "title": "Going Four Times Faster using Multi-Threading",
      "content_text": "Rust makes writing parallel code safe. Rayon makes it easy.",
      "url": "http://worthe-it.co.za/programming/2018/10/03/going-four-times-faster-with-multithreading.html",
      "date_published": "2018-10-03T00:00:00+00:00",
      "author": {
        "name": "Justin Worthe",
        "url": "http://worthe-it.co.za/blog/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "dceefb77-f60e-4864-80e4-1dfb50c52cce",
      "title": "No, pest is not faster than nom",
      "content_text": "But today (October 4th, 2018), the pest website featured a very misleading graph. Yes, a pest 2.0 parser that does not convert the input to Rust types is indeed faster than a nom 4.0 parser that does convert the input to Rust types. But what happens if I write a nom 4.0 parser that does not convert its input to Rust types?",
      "url": "https://unhandledexpression.com/general/2018/10/04/no-pest-is-not-faster-than-nom.html",
      "date_published": "2018-10-04T00:00:00+00:00",
      "author": {
        "name": "Geoffroy Couprie",
        "url": "https://unhandledexpression.com/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "307ed024-4949-4c53-80cf-c1e60a57e0a7",
      "title": "lolbench: automagically and empirically discovering Rust performance regressions",
      "content_text": "lolbench compiles ~350 benchmarks with every Rust nightly. It then runs them and highlights potential performance regressions in the standard library and the output of the compiler. Each toolchain‚Äôs run is summarized with a list of likely candidates, as seen in the image below, and we‚Äôre now getting started using these to safeguard the performance of Rust programs. Come help!",
      "url": "https://blog.anp.lol/rust/2018/09/29/lolbench/",
      "date_published": "2018-09-29T00:00:00+00:00",
      "author": {
        "name": "Adam Perry",
        "url": "https://blog.anp.lol/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "23617503-ac10-4027-bd53-a98ad82c7d1e",
      "title": "The relative performance of C and Rust",
      "content_text": "I reimplemented a body of C software in Rust, and it performed better for the same task; what‚Äôs going on? And is there anything broader we can say about these results?\n\nTo explore this, I ran some statemap rendering tests on SmartOS on a single-socket Haswell server (Xeon E3-1270 v3) running at 3.50GHz. The C version was compiled with GCC 7.3.0 with -O2 level optimizations; the Rust version was compiled with 1.29.0 with --release. All of the tests were run bound to a processor set containing a single core; all were bound to one logical CPU within that core, with the other logical CPU forced to be idle. cpustat was used to gather CPU performance counter data, with one number denoting one run with pic0 programmed to that CPU performance counter. The input file (~30MB compressed) contains 3.5M state changes, and in the default config will generate a ~6MB SVG. ",
      "url": "http://dtrace.org/blogs/bmc/2018/09/28/the-relative-performance-of-c-and-rust/",
      "date_published": "2018-09-29T01:28:17+00:00",
      "author": {
        "name": "Bryan Cantrill",
        "url": "http://dtrace.org/blogs/bmc/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "e3bb7297-9e70-4070-a2aa-8bb8f9a5eaf2",
      "title": "A Sudoku Solver & Generator üî¢",
      "content_text": "For a small side project I‚Äôm working on, I‚Äôm using a Sudoku puzzle solver and puzzle generator that I‚Äôve written in Rust. The experience was fun, so I thought I‚Äôd write up a little bit about the algorithm I‚Äôve used and some interesting stats about how it performs.",
      "url": "https://blog.ryanlevick.com/posts/sudoku-solver-generator/",
      "date_published": "2018-09-16T00:00:00+00:00",
      "author": {
        "name": "Ryan Levick",
        "url": "https://blog.ryanlevick.com/"
      },
      "tags": [
        "Tools and Applications",
        "Performance"
      ]
    },
    {
      "id": "90573eab-4e15-48a4-9c53-8f3466356845",
      "title": "The evolution of performance in ppbert",
      "content_text": "Today I released ppbert 0.8.4. This release also marks the first time that one of my original test files can be pretty printed in less than a second. I‚Äôll use this occasion to look back on ppbert and how I was able to improve its performance, little by little.",
      "url": "https://vfoley.xyz/ppbert-perf-evolution/",
      "date_published": "2018-09-19T00:00:00+00:00",
      "author": {
        "name": "Vincent Foley",
        "url": "http://vfoley.xyz/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "4f00ccb1-9966-4c6d-83e9-0e8032ff68a4",
      "title": "Alacritty now supports scrollback",
      "content_text": "Alacritty, the OpenGL terminal emulator written in Rust, now supports scrollback! Performance has improved, and we've got benchmarks to share.",
      "url": "https://jwilm.io/blog/alacritty-lands-scrollback/",
      "date_published": "2018-09-16T17:00:00-07:00",
      "author": {
        "name": "Joe Wilm",
        "url": "https://jwilm.io/blog"
      },
      "tags": [
        "Tools and Applications",
        "Performance"
      ]
    },
    {
      "id": "48eac964-8486-4cd6-83cb-3bca4ff5b616",
      "title": "Measuring SmallVec Footprint with Smallvectune",
      "content_text": "Rust is all about paying only for what you use, and gives us plenty tools to eliminate unneeded allocation. One of the tools that is used in a lot of crates (crates.io shows 98 dependent crates) is SmallVec. It is also used in the Rust compiler. I recently got around to speed up the operation of getting a SmallVec from a slice of copyable data. In short, they‚Äôre awesome.",
      "url": "https://llogiq.github.io/2018/09/13/smallvec.html",
      "date_published": "2018-09-13T00:00:00+00:00",
      "author": {
        "name": "Llogiq",
        "url": "http://llogiq.github.io/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "2cfb43bc-99fe-4fea-beb0-8e422c55376a",
      "title": "Parallelizing PNG, part 7: Rust profiling on Linux",
      "content_text": "I already covered some inner-loop optimization tricks for low-level Rust code in mtpng, but how do you check how fast bits of your code are anyway?\n\nThe way to go is to use a sampling-based profiler native to your operating system. I‚Äôve done most of my detailed profiling on Linux, using the ‚Äúperf‚Äù tool.",
      "url": "https://brionv.com/log/2018/09/11/parallelizing-png-part-7-rust-profiling-on-linux/",
      "date_published": "2018-09-11T19:52:29+00:00",
      "author": {
        "name": "Brion Vibber",
        "url": "https://brionv.com/log/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "d8bbfe78-53bb-49df-9d7b-092d306492c0",
      "title": "Parallelizing PNG: Choosing Rust for mtpng",
      "content_text": "In my last post I wrapped up the patches to improve perceived performance of screenshots on the Linux GNOME desktop. With that done, why not implement my crazy plan for parallel PNG encoding to speed the actual save time?",
      "url": "https://brionv.com/log/2018/09/09/parallelizing-png-part-5-choosing-rust-for-mtpng/",
      "date_published": "2018-09-09T23:32:41+00:00",
      "author": {
        "name": "Brion Vibber",
        "url": "https://brionv.com/log/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "bf9e8fe4-c788-47c9-9a8a-27ee3fa0b20f",
      "title": "Rust Faster SIMD edition",
      "content_text": "It‚Äôs been a while since I‚Äôve been playing the benchmarksgame with Rust. But I recently found an interesting crate called packed_simd which had a SIMD-ified version of some benchmarks, so as Rust stable now has stdsimd, we should be able to speed up our benchmarks quite a bit.",
      "url": "https://llogiq.github.io/2018/09/06/fast.html",
      "date_published": "2018-09-06T00:00:00+00:00",
      "author": {
        "name": "Llogiq",
        "url": "http://llogiq.github.io/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "3c7f3466-8495-4684-b0c2-e0b26ca9234c",
      "title": "Time difference between L1 cache fetch and memory fetch",
      "content_text": "Aim: Measure how fast a fetch from L1 cache is when compared to a fetch from memory. Instead of writing pure assembly code, we will use Rust's inline assembly feature.",
      "url": "https://nitish.ch/notes/time-difference-between-l1-cache-fetch-and-memory-fetch/",
      "date_published": "2018-09-02T22:15:24+00:00",
      "author": {
        "name": "Nitish Chinta",
        "url": "https://nitish.ch/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "715ee4bf-9164-4c58-aa4f-93f088859281",
      "title": "Benchmarking a Rust web application",
      "content_text": "I set out out my goal 9 for Rustnish: Write benchmark code that compares runtime performance of Rustnish against Varnish. Use cargo bench to execute the benchmarks.\n\nThe basic idea of a performance test here is to send many HTTP requests to the web service (the reverse proxy in this case) and measure how fast the responses arrive back. Comparing the results from Rustnish and Varnish should give us an idea if our performance expectations are holding up.",
      "url": "https://klausi.github.io/rustnish/2018/08/31/benchmarking-a-rust-web-application.html",
      "date_published": "2018-08-31T00:00:00+00:00",
      "author": {
        "name": "klausi",
        "url": "https://klausi.github.io/rustnish/"
      },
      "tags": [
        "Web and Network Services",
        "Performance"
      ]
    },
    {
      "id": "f9bf5234-b8f7-4a0d-9908-e1cf35c6ba8b",
      "title": "Comparing code counters",
      "content_text": "This document is a compilation of various benchmarks and comparisons between code counters, namely tokei, cloc, scc, and loc. This document seeks to compare performance, and accuracy of the code counters. polyglot is not currently included as it was unabled to be installed on the machine at the time of writing.",
      "url": "https://github.com/Aaronepower/tokei/blob/master/COMPARISON.md",
      "date_published": "2018-08-25T21:00:24+00:00",
      "author": {
        "name": "Aaron Power",
        "url": "https://github.com/Aaronepower/tokei"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "ba6b3643-c414-4efe-90a4-4ea6fd45ef3d",
      "title": "Rust, meet q",
      "content_text": "We leverage the elegance of kdb+ and the power of Rust to create data applications that can process data at the rate of tens of GB/second on consumer grade hardware.",
      "url": "https://blog.redsift.com/labs/rust-meet-q/",
      "date_published": "2018-08-23T13:08:16+00:00",
      "author": {
        "name": "Rahul",
        "url": "https://blog.redsift.com/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "d26e4a2d-a00d-4ab2-95e3-326ded5d1fe0",
      "title": "Reading files quickly in Rust",
      "content_text": "With the latest release of 1.27 of Rust (SIMD support) the code counters written in Rust were suddenly a lot faster in Linux. In fact it meant that the fastest one tokei was suddenly faster than my scc for almost all tests. In addition a new project polyglot written in a language I have never heard of ATS popped up which is also now faster than my Go program for any repository when running on a machine with less than 8 cores.",
      "url": "https://boyter.org/posts/reading-files-quickly-in-rust/",
      "date_published": "2018-08-20T00:00:00+00:00",
      "author": {
        "name": "Ben Boyter",
        "url": "https://boyter.org/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "98469a08-b569-403f-a3ed-6049ff91c0b1",
      "title": "Learning SIMD with Rust by finding planets",
      "content_text": "Rust 1.27.0 has brought SIMD (Single Instruction Multiple Data), also known as vectorization, to stable Rust. If you read the announcement, you will see that SIMD should bring performance enhancements to our applications if we learn how to use it properly. But, for that let's first dive into how SIMD works.",
      "url": "https://medium.com/@Razican/learning-simd-with-rust-by-finding-planets-b85ccfb724c3",
      "date_published": "2018-07-02T20:47:57.225+00:00",
      "author": {
        "name": "Iban Eguia",
        "url": "https://medium.com/@Razican"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "495d9d83-2572-43cb-8f9d-c5c404ab83fe",
      "title": "Optimising path tracing: the last 10%",
      "content_text": "In my last post on optimising my Rust path tracer with SIMD I had got withing 10% of my performance target, that is Aras‚Äôs C++ SSE4.1 path tracer. From profiling I had determined that the main differences were MSVC using SSE versions of sinf and cosf and differences between Rayon and enkiTS thread pools. The first thing I tried was implement an SSE2 version of sin_cos based off of Julien Pommier‚Äôs code that I found via a bit of googling. This was enough to get my SSE4.1 implementation to match the performance of Aras‚Äôs SSE4.1 code. I had a slight advantage in that I just call sin_cos as a single function versus separate sin and cos functions, but meh, I‚Äôm calling my performance target reached.\n\nThe other part of this post is about Rust‚Äôs runtime and compile time CPU feature detection and some wrong turns I took along the way.",
      "url": "https://bitshifter.github.io/blog/2018/06/20/the-last-10-percent/",
      "date_published": "2018-06-20T00:00:00+00:00",
      "author": {
        "name": "bitshifter",
        "url": "https://bitshifter.github.io/"
      },
      "tags": [
        "Performance",
        "Games and Graphics"
      ]
    },
    {
      "id": "019cfc86-4560-40cc-8619-30d04e30699b",
      "title": "Optimising path tracing with SIMD",
      "content_text": "Following on from path tracing in parallel with Rayon I had a lot of other optimisations I wanted to try. In particular I want to see if I could match the CPU performance of @aras_p‚Äôs C++ path tracer in Rust. He‚Äôd done a fair amount of optimising so it seemed like a good target to aim for. To get a better comparison I copied his scene and also added his light sampling approach which he talks about here. I also implemented a live render loop mimicking his.",
      "url": "https://bitshifter.github.io/blog/2018/06/04/simd-path-tracing/",
      "date_published": "2018-06-04T00:00:00+00:00",
      "author": {
        "name": "bitshifter",
        "url": "https://bitshifter.github.io/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "9a7909ce-8831-4f06-b32e-55a4a3df9116",
      "title": "How to speed up the Rust compiler some more in 2018",
      "content_text": "Since my last post, rustc-perf ‚Äî the benchmark suite, harness and visualizer ‚Äî has seen some improvements. First, some new benchmarks were added: cargo, ripgrep, sentry-cli, and webrender. Also, the parser benchmark has been removed because it was a toy program and thus not a good benchmark.",
      "url": "https://blog.mozilla.org/nnethercote/2018/06/05/how-to-speed-up-the-rust-compiler-some-more-in-2018/",
      "date_published": "2018-06-05T00:05:01+00:00",
      "author": {
        "name": "Nicholas Nethercote",
        "url": "https://blog.mozilla.org/nnethercote/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "cb90dbcf-0621-4e96-83ca-62deac7e8a3d",
      "title": "RustFest Paris Workshop: Fastware",
      "content_text": "It‚Äôs often said1 that the slowest code is that which has been optimised without benchmarks. You wouldn‚Äôt expect your code to work if you never ran it, so why should you expect it to be fast if you never benchmarked it? Writing good benchmarks is a bit of an art, because it‚Äôs really easy to accidentally write benchmarks that make your code seem fast, when really the compiler is applying some optimisations that work in the side-effect-free world of the benchmark but can no longer get applied when you put it out into the wild.",
      "url": "http://troubles.md/posts/rustfest-2018-workshop/",
      "date_published": "2018-05-22T11:22:48+02:00",
      "author": {
        "name": "troubles.md",
        "url": "http://troubles.md/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "da6bf82a-304e-42bd-9209-fbb8ee975fcd",
      "title": "Improving SmallVec's speed by 60% and why that shouldn't matter to you",
      "content_text": "smallvec is a library by the Servo team for reducing the number of allocations for dynamic arrays in the case that most of those arrays are below a certain size. Because malloc is fast, for many cases it‚Äôs actually slower to use SmallVec than just using Vec because the one-time cost of the initial allocation is dwarfed by the lifetime cost of SmallVec‚Äôs increased complexity. You can see that switching to Vec actually improves speed on many of SmallVec‚Äôs own benchmarks.",
      "url": "http://troubles.md/posts/improving-smallvec/",
      "date_published": "2018-05-17T14:44:51+02:00",
      "author": {
        "name": "troubles.md",
        "url": "http://troubles.md/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "f676f9eb-ea74-4dc5-a393-1f23a7886678",
      "title": "Dropping drops",
      "content_text": "Recently, a benchmark made it to the top of /r/programming, featuring Rust among other languages, and I was a bit surprised to see that the idiomatic Rust program was not competitive with the best-tuned C++ solution. The benchmark implements a binary tree, and the C++ solution leverages raw pointers while Rust would use an Option<Box<Node>> to represent its tree. Since Option knows that Box is non-nullable, it should compile down to a raw pointer. Quickly inspecting the Rust and C++ versions would not let me find where the performance difference came from.",
      "url": "https://barrielle.cedeela.fr/research_page/dropping-drops.html",
      "date_published": "2018-05-17T00:00:00+02:00",
      "author": {
        "name": "Vincent Barrielle",
        "url": "https://barrielle.cedeela.fr/research_page/category/blog.html"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "51352c9c-dac9-4e94-a90f-5e953057a01a",
      "title": "Porting Rust Benchmarks To Criterion",
      "content_text": "A few weeks ago, I set out to convert bytecount‚Äôs benchmarks to criterion, a statistics-driven benchmarking framework started by Jorge Aparicio and maintained by Brook Heisler.\n\nBefore, bytecount used bencher for its benchmarks, which is a straight port of the unstable, nightly-only std::test benchmark framework, extended to work with stable Rust. This was a great benefit compared to std::test, because now we could benchmark on all Rust versions (stable, beta, nightly, some specific version) without needing to fear regressions.",
      "url": "https://llogiq.github.io/2018/05/18/criterion.html",
      "date_published": "2018-05-18T00:00:00+00:00",
      "author": {
        "name": "Llogiq",
        "url": "http://llogiq.github.io/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "a9218983-121e-4d4f-a02f-fd30cb6cf9b2",
      "title": "The Rust compiler is getting faster",
      "content_text": "TL;DR: The Rust compiler has gotten 1.06x‚Äì4x faster over the past month.",
      "url": "https://blog.mozilla.org/nnethercote/2018/05/17/the-rust-compiler-is-getting-faster/",
      "date_published": "2018-05-17T04:08:48+00:00",
      "author": {
        "name": "Nicholas Nethercote",
        "url": "https://blog.mozilla.org/nnethercote/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "2027caf9-9c4c-4e62-b4f3-2c43ff70590b",
      "title": "Optimising CTree and strs",
      "content_text": "Once upon a time, I wrote an interpreter for Stratego Core in Rust, which I named strs. Stratego Core is the core language that Stratego is compiled to before the compiler goes further (to Java, or previously to C). A core language is an intermediate representation that is a subset of the surface language.\n\nWhile I optimised that interpreter quite a bit, I noticed that the CTree (Stratego Core Abstract Syntax Tree) that the compiler spit out for me to interpret was very unoptimised. Therefore one the plans I described at the end of the blog post was a little tool for Copy Propagation on CTree files. This post is about that tool, and the optimisations in the interpreter that made it obsolete again.",
      "url": "http://blog.jeffsmits.net/compsci/2018/05/08/optimising-stratego-core/",
      "date_published": "2018-05-08T00:00:00+00:00",
      "author": {
        "name": "Jeff Smits",
        "url": "http://blog.jeffsmits.net/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "97a47f42-b32a-45df-8473-892b94367048",
      "title": "How a Rust upgrade more than tripled the speed of my code",
      "content_text": "I‚Äôd like to share a quick story about the sheer power of LLVM and the benefits of using higher-level languages over assembly.",
      "url": "http://troubles.md/posts/the-power-of-compilers/",
      "date_published": "2018-05-11T16:07:31+02:00",
      "author": {
        "name": "troubles.md",
        "url": "http://troubles.md/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "d18e865c-71c2-4c7e-85ff-7d84e1999055",
      "title": "Performance experiments with matrix multiplication",
      "content_text": "One of Rust‚Äôs design goals is to be fast. That actually needs two distinct things from the language. First, is it shouldn‚Äôt introduce too much (preferably zero) overhead for its abstractions and be fast out of the box. Many people coming from the high level languages (python, javascript, ‚Ä¶) find this to be the case ‚Äí just type the program, compile it (with --release) and it‚Äôs reasonable fast. The other, no less important, is allowing the programmer to tweak some knobs when trying to squeeze a bit more speed out of the program.\n\nI‚Äôve decided to test the second a bit and see how far I could go. I‚Äôve chosen matrix multiplication as a case study, for several reasons. I‚Äôve played with it before (in my master‚Äôs thesis), it‚Äôs relatively simple and the effects of optimizing it can be great. For simplicity, I‚Äôve decided to multiply only square matrices with power-of-two sizes, but these restrictions can be lifted in a real implementation without significantly loosing performance ‚Äí only the code gets somewhat more complex and hairy.",
      "url": "https://vorner.github.io/2018/05/12/Mat-perf.html",
      "date_published": "2018-05-12T00:00:00+00:00",
      "author": {
        "name": "Michal 'vorner' Vaner",
        "url": "https://vorner.github.io/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "0a6c62ed-f16b-4b57-8ff1-3984e08f204e",
      "title": "How fast can we compile Rust hello world?",
      "content_text": "Seeing Nick Nethercote‚Äôs blog post about speeding up the compiler, I started wondering just how fast could a Rust compiler be? How fast could we compile a simple example? How fast can we compile a Rust hello world?",
      "url": "http://www.jonathanturner.org/2018/05/how-fast-can-we-compile-rust-hello-world.html",
      "date_published": "2018-05-03T00:00:00+00:00",
      "author": {
        "name": "Jonathan Turner",
        "url": "http://www.jonathanturner.org/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "1c59d8b2-c755-4f10-859e-4847be81bc4c",
      "title": "How to speed up the Rust compiler in 2018",
      "content_text": "18 months ago I wrote about some work I did to speed up the Rust compiler (rustc). I‚Äôve recently taken this work up again. Also, in the meantime rustc‚Äôs build system has been replaced and its benchmark suite has been overhauled. So it‚Äôs a good time for an update.",
      "url": "https://blog.mozilla.org/nnethercote/2018/04/30/how-to-speed-up-the-rust-compiler-in-2018/",
      "date_published": "2018-04-30T04:13:45+00:00",
      "author": {
        "name": "Nicholas Nethercote",
        "url": "https://blog.mozilla.org/nnethercote/"
      },
      "tags": [
        "Language",
        "Performance"
      ]
    },
    {
      "id": "d412d980-cc59-4a0b-ab9e-19100f3b8927",
      "title": "Faster Bulletproofs with Ristretto & AVX2",
      "content_text": "A few months ago, B√ºnz, Bootle, Boneh, Poelstra, Wuille, and Maxwell published Bulletproofs, which dramatically improves proof performance both in terms of proof size and verification time. In addition, it allows proving a much wider class of statements than just range proofs.\n\nAt Chain, we (Henry de Valence, Cathie Yun and Oleg Andreev) have been working on a pure-Rust Bulletproofs implementation, whose initial version we are publishing today, together with a set of notes.",
      "url": "https://blog.chain.com/faster-bulletproofs-with-ristretto-avx2-29450b4490cd",
      "date_published": "2018-04-13T19:21:27.639+00:00",
      "author": {
        "name": "Chain",
        "url": "https://blog.chain.com/@chaininc"
      },
      "tags": [
        "Tools and Applications",
        "Performance"
      ]
    },
    {
      "id": "b93c9682-4e53-4a7f-a39b-79d57b2b4737",
      "title": "New sysinfo version (huge performance improvements!)",
      "content_text": "This new version comes with great performance improvements. We're talking about 3x faster on macos, 2x faster on linux and 3x faster on windows (the benchmarks are at the end of the post).",
      "url": "https://blog.guillaume-gomez.fr/articles/2018-04-09+New+sysinfo+version+%28huge+performance+improvements%21%29",
      "date_published": "2018-04-09T00:00:00+00:00",
      "author": {
        "name": "Guillaume Gomez",
        "url": "https://blog.guillaume-gomez.fr/"
      },
      "tags": [
        "Performance",
        "Tools and Applications"
      ]
    },
    {
      "id": "98f65a4a-8501-45e4-bda8-48d5d01306ba",
      "title": "Improving GStreamer performance with tokio",
      "content_text": "For one of our customers at Centricular we were working on a quite interesting project. Their use-case was basically to receive an as-high-as-possible number of audio RTP streams over UDP, transcode them, and then send them out via UDP again. Due to how GStreamer usually works, they were running into some performance issues.\n\nThis blog post will describe the first set of improvements that were implemented for this use-case, together with a minimal benchmark and the results. My colleague Mathieu will follow up with one or two other blog posts with the other improvements and a more full-featured benchmark.\n\nThe short version is that CPU usage decreased by about 65-75%, i.e. allowing 3-4x more streams with the same CPU usage. Also parallelization works better and usage of different CPU cores is more controllable, allowing for better scalability. And a fixed, but configurable number of threads is used, which is independent of the number of streams.",
      "url": "https://coaxion.net/blog/2018/04/improving-gstreamer-performance-on-a-high-number-of-network-streams-by-sharing-threads-between-elements-with-rusts-tokio-crate/",
      "date_published": "2018-04-05T15:21:06+00:00",
      "author": {
        "name": "Sebastian Dr√∂ge",
        "url": "https://coaxion.net/blog/"
      },
      "tags": [
        "Web and Network Services",
        "Performance"
      ]
    },
    {
      "id": "3052579c-dccc-46b8-8d93-bbecfa493992",
      "title": "Speeding Up 'dwarfdump' With Rust",
      "content_text": "Writing a debugger for C++ on Linux, you spend a lot of time examining pretty-printed DWARF debug information using tools like readelf, objdump or dwarfdump. Unfortunately this can be quite slow.\n\nI decided to try to speed dwarfdump up. TL;DR: I reduced the dump time from 506s to 26s by fixing some simple issues and taking advantage of Rust \"fearless parallelism\". I think there are interesting opportunities for speeding up many kinds of command-line tools using Rust and parallelism.",
      "url": "https://robert.ocallahan.org/2018/03/speeding-up-dwarfdump-with-rust.html",
      "date_published": "2018-03-29T14:44:00+13:00",
      "author": {
        "name": "Robert O'Callahan",
        "url": "https://robert.ocallahan.org/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "07825eb3-aaab-46c5-b7e4-680857d73750",
      "title": "Rust + Node.js are awesome!",
      "content_text": "Blazing fast, low requirements, computationally intensive operations on Node.js using Rust",
      "url": "https://itnext.io/rust-node-js-are-awesome-a50d63411773",
      "date_published": "2018-03-27T21:50:20.148+00:00",
      "author": {
        "name": "Benjam√≠n Calder√≥n",
        "url": "https://itnext.io/@benjcal"
      },
      "tags": [
        "Web and Network Services",
        "Performance"
      ]
    },
    {
      "id": "655ac748-e1e9-4fa4-b12a-2dc7c2e88fa7",
      "title": "Building a fast Electron app with Rust",
      "content_text": "When I built Finda, I wanted it to be fast ‚Äî specifically, to respond to all user input within 16 milliseconds.\n\nGiven this goal, you might be surprised to learn that Finda is built with Electron, a framework that‚Äôs often decried for being the opposite of fast.",
      "url": "https://keminglabs.com/blog/building-a-fast-electron-app-with-rust/",
      "date_published": "2018-03-18T00:00:00+11:00",
      "author": {
        "name": "Kevin J. Lynagh",
        "url": "https://keminglabs.com/blog/"
      },
      "tags": [
        "Tools and Applications",
        "Performance"
      ]
    },
    {
      "id": "0ebef41d-c7b1-424a-a120-ebf1098bbe38",
      "title": "Three Algorithm Optimizations Outside [Place], [Other place]",
      "content_text": "Recently, I came across an ad for a job that had a precondition for application: it required you to first solve a ‚ú®programming challenge‚ú®:",
      "url": "https://medium.com/@urschrei/three-algorithm-optimizations-outside-place-other-place-294de5a68f27",
      "date_published": "2018-02-28T17:12:42.361+00:00",
      "author": {
        "name": "Steph",
        "url": "https://medium.com/@urschrei"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "5e5df82f-aba3-4832-bbe6-e995b2e544ef",
      "title": "Criterion.rs v0.2 - a statistics-driven benchmarking library for Rust",
      "content_text": "Criterion.rs is a statistics-driven benchmarking library for Rust. It provides precise measurements of changes in the performance of benchmarked code, and gives strong statistical confidence that apparent performance changes are real and not simply noise. Clear output, a simple API and reasonable defaults make it easy to use even for developers without a background in statistics. Unlike the benchmarking harness provided by Rust, Criterion.rs can be used with stable versions of the compiler.",
      "url": "https://bheisler.github.io/post/criterion-rs-0-2/",
      "date_published": "2018-02-05T07:00:00-06:00",
      "author": {
        "name": "Brook Heisler",
        "url": "https://bheisler.github.io/"
      },
      "tags": [
        "Performance",
        "Crates"
      ]
    },
    {
      "id": "1ccb8993-1118-4eb4-a1fb-0c6146948662",
      "title": "Benchmark of different Async approaches in Rust",
      "content_text": "The story about Rust‚Äôs async is still a bit in flux. There‚Äôs a bunch of libraries with their pros and cons and different approaches. Even I‚Äôm a bit to blame for that, as I‚Äôm writing one of my own, called Corona.",
      "url": "https://vorner.github.io/async-bench.html",
      "date_published": "2018-02-03T11:16:55+00:00",
      "author": {
        "name": "Michal 'vorner' Vaner",
        "url": "https://vorner.github.io/"
      },
      "tags": [
        "Performance"
      ]
    },
    {
      "id": "e1a29851-ab4c-4739-a41f-56e9c783f5e4",
      "title": "Faster Progress Report 2",
      "content_text": "faster began as a yak shave, created to aid baseüíØ in its quest to become the fastest meme on Github. Writing an explicit AVX2-accelerated version of baseüíØ's encoder and decoder, then realizing I'd have to do the same thing again to see the speedups on my Ivy Bridge desktop, pushed me to make this library. Months later, it has blossomed into its own project, and has eclipsed baseüíØ in both popularity and promise.",
      "url": "https://adamniederer.com/blog/faster-pr-2.html",
      "date_published": "2018-01-28T22:14:41+00:00",
      "author": {
        "name": "Adam Niederer",
        "url": "https://adamniederer.com/blog/blog.html"
      },
      "tags": [
        "Performance",
        "Crates"
      ]
    }
  ]
}